{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f562e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'  # or 'tensorflow' or 'jax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4deeb9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import keras\n",
    "import optuna\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.keras\n",
    "\n",
    "from mlflow.keras import MlflowCallback\n",
    "from mlflow.models import infer_signature, ModelSignature\n",
    "from mlflow.types import Schema, TensorSpec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2d80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The set_experiment API creates a new experiment if it doesn't exist.\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")                # Point to the remote MLflow server via REST API\n",
    "mlflow.set_experiment(\"MNIST with Keras within MLFLow\")         # Set the experiment name\n",
    "\n",
    "# IMPORTANT: Enable system metrics monitoring\n",
    "mlflow.config.enable_system_metrics_logging()                   # Enable system metrics logging\n",
    "mlflow.config.set_system_metrics_sampling_interval(1)           # The frequency of logging of the metrics. By default it's 10s, but here we set it to 1s\n",
    "mlflow.config.set_system_metrics_samples_before_logging(3)      # The number of samples to aggregate\n",
    "\n",
    "# The actual logging time window is the product of MLFLOW_SYSTEM_METRICS_SAMPLING_INTERVAL and MLFLOW_SYSTEM_METRICS_SAMPLES_BEFORE_LOGGING. For example, if the sample interval is set to 2 seconds and samples before logging to 3, then system metrics will be collected every 2 seconds, then after 3 samples are collected (2 * 3 = 6s), we aggregate the metrics and log to MLflow server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9285d5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and prepare data\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "574282ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = None\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Alternative using accelerate library if PyTorch version >= 2.6\n",
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adfe8c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=(784,)),\n",
    "            keras.layers.Dense(512, activation='relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(256, activation='relu'),\n",
    "            keras.layers.Dropout(0.2),\n",
    "            keras.layers.Dense(10, activation='softmax')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb3076fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "params = {\"epochs\": 10,\n",
    "          \"batch_size\": 128,\n",
    "          \"learning_rate\": 0.001,\n",
    "          \"optimizer\": \"adam\",\n",
    "          \"loss_function\": \"categorical_crossentropy\",\n",
    "          \"dropout_rate\": 0.2,\n",
    "          \"hidden_units\": [512, 256]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39dc5fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile model\n",
    "model = create_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=params[\"learning_rate\"]),\n",
    "              loss=params[\"loss_function\"],\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e56c786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autologging for Pytorch/Keras\n",
    "mlflow.keras.autolog(registered_model_name=\"Keras_MNIST_autolog_model\", # Name of the model in MLflow Model Registry\n",
    "                     log_models=True,                                   # Save the model in MLflow Model Registry at the end of the run\n",
    "                     log_every_n_steps=params['batch_size'],            # Log metrics every n steps (batches)  \n",
    "                     log_every_epoch=False,                             # Disabling logging metrics at the end of every epoch as we are logging every n steps\n",
    "                     log_model_signatures=True,                         # Log the model signature (input and output schema)  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1fc3bac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:24:43 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:24:43 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pytorch model on GPU/TPU...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:24:53 WARNING mlflow.keras.autologging: Unrecognized dataset type <class 'torch.Tensor'>. Dataset logging skipped.\n",
      "2025/12/12 12:24:53 WARNING mlflow.keras.autologging: Failed to log dataset information to MLflow. Reason: int() argument must be a string, a bytes-like object or a real number, not 'builtin_function_or_method'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9189 - loss: 0.2697 - val_accuracy: 0.9635 - val_loss: 0.1168\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.1081 - val_accuracy: 0.9749 - val_loss: 0.0753\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9768 - loss: 0.0766 - val_accuracy: 0.9778 - val_loss: 0.0707\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9805 - loss: 0.0597 - val_accuracy: 0.9804 - val_loss: 0.0622\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9840 - loss: 0.0487 - val_accuracy: 0.9813 - val_loss: 0.0588\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9869 - loss: 0.0400 - val_accuracy: 0.9818 - val_loss: 0.0655\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9883 - loss: 0.0345 - val_accuracy: 0.9817 - val_loss: 0.0600\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.9893 - loss: 0.0317 - val_accuracy: 0.9814 - val_loss: 0.0665\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9909 - loss: 0.0279 - val_accuracy: 0.9830 - val_loss: 0.0612\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0228 - val_accuracy: 0.9834 - val_loss: 0.0635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:25:49 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "Registered model 'Keras_MNIST_autolog_model' already exists. Creating a new version of this model...\n",
      "2025/12/12 12:25:59 INFO mlflow.store.model_registry.abstract_store: Waiting up to 300 seconds for model version to finish creation. Model name: Keras_MNIST_autolog_model, version 11\n",
      "Created version '11' of model 'Keras_MNIST_autolog_model'.\n",
      "2025/12/12 12:26:00 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:26:00 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run autolog_run at: http://127.0.0.1:5000/#/experiments/7/runs/7cc365da7d144aa283b7477b9655471c\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='autolog_run') as run:\n",
    "    if os.environ['KERAS_BACKEND'] == 'torch':\n",
    "        if device.type == 'cuda' or device.type == 'mps':\n",
    "            print(\"Training Pytorch model on GPU/TPU...\\n\")\n",
    "            \n",
    "            x_train_torch = torch.tensor(x_train).to(device)    # Creating a torch tensor version of x_train\n",
    "            x_test_torch = torch.tensor(x_test).to(device)      # Creating a torch tensor version of x_test\n",
    "            \n",
    "            model.fit(x_train_torch,\n",
    "                        y_train,\n",
    "                        batch_size=params[\"batch_size\"],\n",
    "                        epochs=params[\"epochs\"],\n",
    "                        validation_data=(x_test_torch, y_test),\n",
    "                        verbose=1)\n",
    "        else:\n",
    "            print(\"GPU/TPU not available. Training Pytorch model on CPU...\\n\")\n",
    "            model.fit(x_train,\n",
    "                    y_train,\n",
    "                    batch_size=params[\"batch_size\"],\n",
    "                    epochs=params[\"epochs\"],\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    verbose=1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3289686e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:26:00 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:26:00 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "2025/12/12 12:26:02 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:26:02 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run autolog_run at: http://127.0.0.1:5000/#/experiments/7/runs/7cc365da7d144aa283b7477b9655471c\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Test accuracy: 0.9834\n"
     ]
    }
   ],
   "source": [
    "# Get the last run (autologging created it)\n",
    "last_run = mlflow.last_active_run()   # or mlflow.search_runs() to query\n",
    "\n",
    "# Reâ€‘attach\n",
    "with mlflow.start_run(run_id=last_run.info.run_id):\n",
    "\n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    mlflow.log_metrics({\"test_loss\": test_loss, \"test_accuracy\": test_accuracy})\n",
    "\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d25fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stopping autolog runs so that it doesn't interfere with future runs\n",
    "mlflow.autolog(disable=True)\n",
    "mlflow.keras.autolog(disable=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8e9e8e",
   "metadata": {},
   "source": [
    "# Manually Logging Keras Experiments\n",
    "\n",
    "While MLflow provides seamless autologging integration with Keras/TensorFlow via either **mlflow.tensorflow.autolog()** or **mlflow.autolog()**, it works only with **model.fit()** and needs to be executed before we invoke model training via the same. In comparison, if we wish to customise our model training, we need to manually log all the details we wish to capture.\n",
    "\n",
    "For more control over what gets logged, you can manually instrument your Keras training code using MLflow's logging APIs:\n",
    "\n",
    "**mlflow.log_metric() / mlflow.log_metrics()**: Log metrics such as accuracy and loss during training\n",
    "**mlflow.log_param() / mlflow.log_params()**: Log parameters such as learning rate and batch size\n",
    "**mlflow.keras.log_model()**: Save your Keras model to MLflow\n",
    "**mlflow.log_artifact()**: Log artifacts such as model checkpoints and plots\n",
    "\n",
    "## Using MLflow's Keras Callback\n",
    "\n",
    "MLflow provides a built-in callback for Keras that simplifies experiment tracking. The **mlflow.keras.MlflowCallback()** integrates seamlessly with your Keras training loop. The MlflowCallback supports various configuration options. Some of these options are also available out-of-box for **mlflow.autolog()**. We have demonstrated some of the options in the previous code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d739ef75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:26:02 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:26:02 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pytorch model on GPU/TPU...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9913 - loss: 0.0253 - val_accuracy: 0.9827 - val_loss: 0.0618\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9925 - loss: 0.0222 - val_accuracy: 0.9831 - val_loss: 0.0655\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9924 - loss: 0.0225 - val_accuracy: 0.9844 - val_loss: 0.0643\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9932 - loss: 0.0204 - val_accuracy: 0.9835 - val_loss: 0.0675\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9937 - loss: 0.0196 - val_accuracy: 0.9835 - val_loss: 0.0700\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9948 - loss: 0.0156 - val_accuracy: 0.9838 - val_loss: 0.0705\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0146 - val_accuracy: 0.9830 - val_loss: 0.0762\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9940 - loss: 0.0176 - val_accuracy: 0.9835 - val_loss: 0.0749\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9952 - loss: 0.0143 - val_accuracy: 0.9829 - val_loss: 0.0759\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0158 - val_accuracy: 0.9837 - val_loss: 0.0770\n",
      "\u001b[1m4/4\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "Test accuracy: 0.9837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:27:02 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:27:02 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run manual_run at: http://127.0.0.1:5000/#/experiments/7/runs/4b46cf11ef10408e935382a4c2ed6a42\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "# Use MLflow's built-in callback\n",
    "mlflow_callback = MlflowCallback(log_every_epoch=False, log_every_n_steps=params['batch_size'])       # Log metrics every 5 batches instead of every epoch\n",
    "\n",
    "with mlflow.start_run(run_name=\"manual_run\",\n",
    "                      log_system_metrics=True) as run:\n",
    "\n",
    "    if os.environ['KERAS_BACKEND'] == 'torch':\n",
    "        if device.type == 'cuda' or device.type == 'mps':\n",
    "            print(\"Training Pytorch model on GPU/TPU...\\n\")\n",
    "\n",
    "            x_train_torch = torch.tensor(x_train).to(device)    # Creating a torch tensor version of x_train\n",
    "            x_test_torch = torch.tensor(x_test).to(device)      # Creating a torch tensor version of x_test\n",
    "            \n",
    "            history = model.fit(x_train_torch,\n",
    "                                y_train,\n",
    "                                batch_size=params[\"batch_size\"],\n",
    "                                epochs=params[\"epochs\"],\n",
    "                                validation_data=(x_test_torch, y_test),\n",
    "                                callbacks=[mlflow_callback],\n",
    "                                verbose=1)\n",
    "        else:\n",
    "            print(\"GPU/TPU not available. Training Pytorch model on CPU...\\n\")\n",
    "            history = model.fit(x_train,\n",
    "                                y_train,\n",
    "                                batch_size=params[\"batch_size\"],\n",
    "                                epochs=params[\"epochs\"],\n",
    "                                validation_data=(x_test, y_test),\n",
    "                                callbacks=[mlflow_callback],\n",
    "                                verbose=1)\n",
    "            \n",
    "            \n",
    "    # Evaluate model\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    mlflow.log_metrics({\"test_loss\": test_loss, \"test_accuracy\": test_accuracy})\n",
    "\n",
    "    # Prepare sample data for signature inference\n",
    "    sample_input = x_test[:100]\n",
    "    sample_predictions = model.predict(sample_input)\n",
    "    # Infer signature from sample data\n",
    "    signature = infer_signature(sample_input, sample_predictions)\n",
    "\n",
    "    # Define input and output schemas, in case infer_signature is not working as desired\n",
    "    # input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 784))])\n",
    "    # output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 10))])\n",
    "    # signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "    # Log the trained model\n",
    "    mlflow.keras.log_model(model, name=\"Keras_MNIST_manual_model\", signature=signature)\n",
    "\n",
    "    print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11577c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:27:02 WARNING mlflow.keras.save: You are saving a Keras model without specifying model signature.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m2025/12/12 12:27:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee83e071a4844999a0d59c162e1c32c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Predictions: [[2.41250874e-14 2.84437214e-13 5.25287618e-14 1.00005206e-10\n",
      "  2.50366913e-18 3.33660869e-17 2.65959531e-19 1.00000000e+00\n",
      "  5.19692406e-16 1.46417156e-09]\n",
      " [7.95408119e-14 2.30431869e-08 1.00000000e+00 9.23568134e-14\n",
      "  2.45602179e-25 9.01774900e-17 2.22895128e-18 3.74190611e-15\n",
      "  9.81608351e-17 4.22657460e-28]\n",
      " [4.37706658e-16 1.00000000e+00 1.85822406e-15 5.50810901e-17\n",
      "  9.65283825e-11 1.05247903e-13 7.40667239e-13 1.76222384e-10\n",
      "  1.53264557e-09 9.37823698e-15]\n",
      " [1.00000000e+00 6.30552237e-17 7.36533265e-11 8.76725857e-15\n",
      "  4.20296190e-14 1.66238125e-15 1.27962108e-09 1.64620346e-12\n",
      "  6.37423111e-13 1.61446939e-10]\n",
      " [1.26752400e-10 1.48517847e-11 9.90439154e-12 2.46111299e-16\n",
      "  9.99994755e-01 3.87896150e-13 3.57848679e-13 6.91232005e-09\n",
      "  2.57117660e-10 5.18005982e-06]]\n"
     ]
    }
   ],
   "source": [
    "# Load and use the model\n",
    "model_info = mlflow.keras.log_model(model, name=\"Keras_MNIST_autolog_model\")\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "# Make predictions\n",
    "predictions = loaded_model.predict(x_test[:5])\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c38aa80",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning with Keras and MLflow\n",
    "Combine Keras with hyperparameter tuning libraries while tracking everything in MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f04ba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_float(\"learning_rate\", 1e-5, 1e-1, log=True)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128])\n",
    "    hidden_units = trial.suggest_categorical(\"hidden_units\", [64, 128, 256, 512])\n",
    "    dropout_rate = trial.suggest_float(\"dropout_rate\", 0.1, 0.5)\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log trial parameters\n",
    "        mlflow.log_params({\"learning_rate\": lr,\n",
    "                           \"batch_size\": batch_size,\n",
    "                           \"hidden_units\": hidden_units,\n",
    "                           \"dropout_rate\": dropout_rate\n",
    "                           })\n",
    "\n",
    "        # Create model with suggested parameters\n",
    "        model = keras.Sequential([keras.Input(shape=(784,)),\n",
    "                                  keras.layers.Dense(hidden_units, activation='relu'),\n",
    "                                  keras.layers.Dropout(dropout_rate),\n",
    "                                  keras.layers.Dense(256, activation='relu'),\n",
    "                                  keras.layers.Dropout(dropout_rate),\n",
    "                                  keras.layers.Dense(10, activation='softmax')\n",
    "                            ])\n",
    "\n",
    "        model.compile(optimizer=keras.optimizers.Adam(learning_rate=lr),\n",
    "                      loss=\"categorical_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])\n",
    "        \n",
    "        if os.environ['KERAS_BACKEND'] == 'torch':\n",
    "            if device.type == 'cuda' or device.type == 'mps':\n",
    "                print(\"Training Pytorch model on GPU/TPU...\\n\")\n",
    "\n",
    "                x_train_torch = torch.tensor(x_train).to(device)    # Creating a torch tensor version of x_train\n",
    "                \n",
    "                # Train model\n",
    "                history = model.fit(x_train_torch,\n",
    "                                    y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=10,\n",
    "                                    validation_split=0.2,\n",
    "                                    verbose=1)\n",
    "                \n",
    "            else:\n",
    "                print(\"GPU/TPU not available. Training Pytorch model on CPU...\\n\")\n",
    "                history = model.fit(x_train,\n",
    "                                    y_train,\n",
    "                                    batch_size=batch_size,\n",
    "                                    epochs=10,\n",
    "                                    validation_split=0.2,\n",
    "                                    verbose=1)\n",
    "                \n",
    "        # Evaluate model\n",
    "        val_loss = max(history.history[\"val_loss\"])\n",
    "        val_accuracy = max(history.history[\"val_accuracy\"])\n",
    "        mlflow.log_metrics({\"val_loss\": val_loss, \"val_accuracy\": val_accuracy})\n",
    "\n",
    "        return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "25969ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:27:09 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:27:09 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n",
      "[I 2025-12-12 12:27:09,263] A new study created in memory with name: no-name-6a57ae06-c4f5-4033-8427-b7894e278f9c\n",
      "2025/12/12 12:27:09 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:27:09 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.4730 - loss: 1.7738 - val_accuracy: 0.7928 - val_loss: 1.0020\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.7554 - loss: 0.8675 - val_accuracy: 0.8693 - val_loss: 0.5244\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8174 - loss: 0.6134 - val_accuracy: 0.8937 - val_loss: 0.4043\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8460 - loss: 0.5162 - val_accuracy: 0.9026 - val_loss: 0.3513\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8659 - loss: 0.4571 - val_accuracy: 0.9097 - val_loss: 0.3183\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8754 - loss: 0.4192 - val_accuracy: 0.9163 - val_loss: 0.2952\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8856 - loss: 0.3891 - val_accuracy: 0.9206 - val_loss: 0.2768\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8921 - loss: 0.3648 - val_accuracy: 0.9240 - val_loss: 0.2628\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.8983 - loss: 0.3471 - val_accuracy: 0.9269 - val_loss: 0.2509\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 10ms/step - accuracy: 0.9025 - loss: 0.3309 - val_accuracy: 0.9302 - val_loss: 0.2397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:28:28 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:28:29 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:28:29,002] Trial 0 finished with value: 0.9302499890327454 and parameters: {'learning_rate': 3.367454532946405e-05, 'batch_size': 64, 'hidden_units': 64, 'dropout_rate': 0.2046811041415484}. Best is trial 0 with value: 0.9302499890327454.\n",
      "2025/12/12 12:28:29 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:28:29 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run mercurial-colt-426 at: http://127.0.0.1:5000/#/experiments/7/runs/8b307511ba584b0588f1e9ef0eef38b9\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.7558 - loss: 0.9671 - val_accuracy: 0.8988 - val_loss: 0.4272\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7744 - loss: 0.9113 - val_accuracy: 0.8899 - val_loss: 0.5097\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.7809 - loss: 0.9257 - val_accuracy: 0.8573 - val_loss: 0.7098\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.7694 - loss: 0.9832 - val_accuracy: 0.8798 - val_loss: 0.6021\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.7926 - loss: 0.9199 - val_accuracy: 0.8833 - val_loss: 0.5947\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.7915 - loss: 0.9518 - val_accuracy: 0.8941 - val_loss: 0.5025\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.7954 - loss: 0.9576 - val_accuracy: 0.8796 - val_loss: 0.5994\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.7935 - loss: 0.9439 - val_accuracy: 0.8826 - val_loss: 0.5875\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.8019 - loss: 0.9552 - val_accuracy: 0.8889 - val_loss: 0.6270\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.7950 - loss: 0.9833 - val_accuracy: 0.8963 - val_loss: 0.5896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:31:27 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:31:27 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:31:27,281] Trial 1 finished with value: 0.8987500071525574 and parameters: {'learning_rate': 0.01228422893278514, 'batch_size': 32, 'hidden_units': 512, 'dropout_rate': 0.48629348360337743}. Best is trial 0 with value: 0.9302499890327454.\n",
      "2025/12/12 12:31:27 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:31:27 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run stylish-hog-447 at: http://127.0.0.1:5000/#/experiments/7/runs/624fdd48066246a5b518592f3d200962\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.8208 - loss: 0.5786 - val_accuracy: 0.9411 - val_loss: 0.2018\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9261 - loss: 0.2532 - val_accuracy: 0.9582 - val_loss: 0.1388\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9441 - loss: 0.1899 - val_accuracy: 0.9663 - val_loss: 0.1147\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9546 - loss: 0.1523 - val_accuracy: 0.9697 - val_loss: 0.1005\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9607 - loss: 0.1295 - val_accuracy: 0.9700 - val_loss: 0.0968\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9656 - loss: 0.1163 - val_accuracy: 0.9731 - val_loss: 0.0864\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9685 - loss: 0.1026 - val_accuracy: 0.9753 - val_loss: 0.0831\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0919 - val_accuracy: 0.9757 - val_loss: 0.0775\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9756 - loss: 0.0803 - val_accuracy: 0.9767 - val_loss: 0.0750\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9765 - loss: 0.0762 - val_accuracy: 0.9780 - val_loss: 0.0772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:32:55 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:32:55 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:32:55,691] Trial 2 finished with value: 0.9779999852180481 and parameters: {'learning_rate': 0.0002835618662359073, 'batch_size': 64, 'hidden_units': 512, 'dropout_rate': 0.49906152030569617}. Best is trial 2 with value: 0.9779999852180481.\n",
      "2025/12/12 12:32:55 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:32:55 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run dazzling-wasp-40 at: http://127.0.0.1:5000/#/experiments/7/runs/47f57cf0860a44ceaeb9300f5b1b6a29\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.7742 - loss: 0.7133 - val_accuracy: 0.9250 - val_loss: 0.2466\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.8847 - loss: 0.3821 - val_accuracy: 0.9413 - val_loss: 0.1968\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9029 - loss: 0.3212 - val_accuracy: 0.9494 - val_loss: 0.1713\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9115 - loss: 0.2941 - val_accuracy: 0.9565 - val_loss: 0.1504\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9188 - loss: 0.2687 - val_accuracy: 0.9580 - val_loss: 0.1420\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9228 - loss: 0.2548 - val_accuracy: 0.9614 - val_loss: 0.1331\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9276 - loss: 0.2359 - val_accuracy: 0.9622 - val_loss: 0.1319\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9287 - loss: 0.2296 - val_accuracy: 0.9617 - val_loss: 0.1323\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9310 - loss: 0.2213 - val_accuracy: 0.9625 - val_loss: 0.1281\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 13ms/step - accuracy: 0.9363 - loss: 0.2082 - val_accuracy: 0.9632 - val_loss: 0.1223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:34:22 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:34:22 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:34:22,356] Trial 3 finished with value: 0.9631666541099548 and parameters: {'learning_rate': 0.0006701044813212725, 'batch_size': 64, 'hidden_units': 64, 'dropout_rate': 0.4663812587303746}. Best is trial 2 with value: 0.9779999852180481.\n",
      "2025/12/12 12:34:22 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:34:22 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run unique-fly-180 at: http://127.0.0.1:5000/#/experiments/7/runs/4eaf3413fa8b457f94964478c60ffc90\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9189 - loss: 0.2712 - val_accuracy: 0.9688 - val_loss: 0.1094\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9642 - loss: 0.1153 - val_accuracy: 0.9715 - val_loss: 0.0937\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9741 - loss: 0.0842 - val_accuracy: 0.9728 - val_loss: 0.0945\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9783 - loss: 0.0674 - val_accuracy: 0.9780 - val_loss: 0.0745\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9817 - loss: 0.0552 - val_accuracy: 0.9775 - val_loss: 0.0775\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9837 - loss: 0.0492 - val_accuracy: 0.9791 - val_loss: 0.0813\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9870 - loss: 0.0393 - val_accuracy: 0.9772 - val_loss: 0.0857\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9881 - loss: 0.0360 - val_accuracy: 0.9770 - val_loss: 0.0865\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9896 - loss: 0.0320 - val_accuracy: 0.9756 - val_loss: 0.0916\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9893 - loss: 0.0318 - val_accuracy: 0.9791 - val_loss: 0.0841\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:37:20 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:37:20 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:37:20,635] Trial 4 finished with value: 0.9790833592414856 and parameters: {'learning_rate': 0.0006229619236470463, 'batch_size': 32, 'hidden_units': 512, 'dropout_rate': 0.22810009149215713}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:37:20 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:37:20 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run placid-shrew-426 at: http://127.0.0.1:5000/#/experiments/7/runs/232adcbc6a78491190b9f73d4d15228d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9027 - loss: 0.3151 - val_accuracy: 0.9643 - val_loss: 0.1239\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9470 - loss: 0.1784 - val_accuracy: 0.9679 - val_loss: 0.1105\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9561 - loss: 0.1508 - val_accuracy: 0.9703 - val_loss: 0.1006\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9602 - loss: 0.1341 - val_accuracy: 0.9722 - val_loss: 0.0991\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9642 - loss: 0.1228 - val_accuracy: 0.9762 - val_loss: 0.0940\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9666 - loss: 0.1149 - val_accuracy: 0.9753 - val_loss: 0.0882\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9696 - loss: 0.1065 - val_accuracy: 0.9758 - val_loss: 0.0920\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9702 - loss: 0.1032 - val_accuracy: 0.9768 - val_loss: 0.0863\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9720 - loss: 0.0995 - val_accuracy: 0.9758 - val_loss: 0.0931\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9737 - loss: 0.0945 - val_accuracy: 0.9768 - val_loss: 0.0916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:40:17 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:40:17 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:40:17,677] Trial 5 finished with value: 0.9768333435058594 and parameters: {'learning_rate': 0.0014812314577237866, 'batch_size': 32, 'hidden_units': 512, 'dropout_rate': 0.42244007414791496}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:40:17 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:40:17 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run aged-tern-806 at: http://127.0.0.1:5000/#/experiments/7/runs/6abe45fa6d0b4971b3fb936999e34fcb\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.7562 - loss: 0.8783 - val_accuracy: 0.9059 - val_loss: 0.3378\n",
      "Epoch 2/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.8919 - loss: 0.3693 - val_accuracy: 0.9252 - val_loss: 0.2570\n",
      "Epoch 3/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9127 - loss: 0.2993 - val_accuracy: 0.9358 - val_loss: 0.2219\n",
      "Epoch 4/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9244 - loss: 0.2599 - val_accuracy: 0.9427 - val_loss: 0.1983\n",
      "Epoch 5/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9317 - loss: 0.2338 - val_accuracy: 0.9481 - val_loss: 0.1817\n",
      "Epoch 6/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9369 - loss: 0.2116 - val_accuracy: 0.9515 - val_loss: 0.1677\n",
      "Epoch 7/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9417 - loss: 0.1961 - val_accuracy: 0.9541 - val_loss: 0.1572\n",
      "Epoch 8/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 11ms/step - accuracy: 0.9467 - loss: 0.1804 - val_accuracy: 0.9571 - val_loss: 0.1462\n",
      "Epoch 9/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 11ms/step - accuracy: 0.9506 - loss: 0.1659 - val_accuracy: 0.9601 - val_loss: 0.1376\n",
      "Epoch 10/10\n",
      "\u001b[1m750/750\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9520 - loss: 0.1573 - val_accuracy: 0.9604 - val_loss: 0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:41:42 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:41:42 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:41:42,822] Trial 6 finished with value: 0.9604166746139526 and parameters: {'learning_rate': 0.00012588097393413222, 'batch_size': 64, 'hidden_units': 64, 'dropout_rate': 0.10541049222216695}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:41:42 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:41:42 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run carefree-crane-746 at: http://127.0.0.1:5000/#/experiments/7/runs/15ab07b959064931a169887cafc3725d\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.8803 - loss: 0.4195 - val_accuracy: 0.9310 - val_loss: 0.2385\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9156 - loss: 0.3220 - val_accuracy: 0.9465 - val_loss: 0.2185\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9225 - loss: 0.3081 - val_accuracy: 0.9513 - val_loss: 0.2002\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9262 - loss: 0.3096 - val_accuracy: 0.9478 - val_loss: 0.2175\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9309 - loss: 0.2820 - val_accuracy: 0.9578 - val_loss: 0.1873\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9342 - loss: 0.2756 - val_accuracy: 0.9513 - val_loss: 0.2046\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9357 - loss: 0.2879 - val_accuracy: 0.9515 - val_loss: 0.2055\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9368 - loss: 0.2771 - val_accuracy: 0.9482 - val_loss: 0.2210\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.9369 - loss: 0.2785 - val_accuracy: 0.9545 - val_loss: 0.2140\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 13ms/step - accuracy: 0.9396 - loss: 0.2672 - val_accuracy: 0.9596 - val_loss: 0.2053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:44:44 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:44:44 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:44:44,669] Trial 7 finished with value: 0.9595833420753479 and parameters: {'learning_rate': 0.008141965087597802, 'batch_size': 32, 'hidden_units': 128, 'dropout_rate': 0.1919093147335513}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:44:44 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:44:44 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run carefree-pug-411 at: http://127.0.0.1:5000/#/experiments/7/runs/196ede7a475e4c0ea32b991acfdd85fb\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.3065 - loss: 2.0172 - val_accuracy: 0.7737 - val_loss: 1.4149\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.6144 - loss: 1.3007 - val_accuracy: 0.8478 - val_loss: 0.7636\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7187 - loss: 0.9180 - val_accuracy: 0.8759 - val_loss: 0.5367\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7714 - loss: 0.7413 - val_accuracy: 0.8909 - val_loss: 0.4395\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8045 - loss: 0.6380 - val_accuracy: 0.8980 - val_loss: 0.3845\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8270 - loss: 0.5715 - val_accuracy: 0.9077 - val_loss: 0.3467\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8418 - loss: 0.5239 - val_accuracy: 0.9116 - val_loss: 0.3224\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.8528 - loss: 0.4869 - val_accuracy: 0.9162 - val_loss: 0.3027\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8645 - loss: 0.4571 - val_accuracy: 0.9202 - val_loss: 0.2861\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.8730 - loss: 0.4338 - val_accuracy: 0.9233 - val_loss: 0.2716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:45:30 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:45:30 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:45:30,040] Trial 8 finished with value: 0.9232500195503235 and parameters: {'learning_rate': 2.543073665626789e-05, 'batch_size': 128, 'hidden_units': 256, 'dropout_rate': 0.46918858589523194}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:45:30 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:45:30 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run caring-frog-795 at: http://127.0.0.1:5000/#/experiments/7/runs/a611a3afc0d44e09bcf98fc2665a264f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9019 - loss: 0.3212 - val_accuracy: 0.9613 - val_loss: 0.1332\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9482 - loss: 0.1736 - val_accuracy: 0.9690 - val_loss: 0.1066\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9580 - loss: 0.1427 - val_accuracy: 0.9695 - val_loss: 0.1057\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9621 - loss: 0.1235 - val_accuracy: 0.9715 - val_loss: 0.0988\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9663 - loss: 0.1147 - val_accuracy: 0.9689 - val_loss: 0.1115\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9688 - loss: 0.1028 - val_accuracy: 0.9722 - val_loss: 0.0975\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9693 - loss: 0.1022 - val_accuracy: 0.9741 - val_loss: 0.0910\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0937 - val_accuracy: 0.9738 - val_loss: 0.0992\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.0910 - val_accuracy: 0.9756 - val_loss: 0.0877\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9747 - loss: 0.0823 - val_accuracy: 0.9781 - val_loss: 0.0805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:48:16 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:48:16 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:48:16,020] Trial 9 finished with value: 0.9780833125114441 and parameters: {'learning_rate': 0.0014283810799751628, 'batch_size': 32, 'hidden_units': 256, 'dropout_rate': 0.3574990608630074}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:48:16 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:48:16 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run rogue-rat-650 at: http://127.0.0.1:5000/#/experiments/7/runs/5b68a211ae5a454ba1363492d606138f\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4415 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.1019 - loss: 14.4764 - val_accuracy: 0.1035 - val_loss: 14.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:48:57 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:48:57 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:48:57,537] Trial 10 finished with value: 0.10350000113248825 and parameters: {'learning_rate': 0.0716092648522239, 'batch_size': 128, 'hidden_units': 128, 'dropout_rate': 0.27800724961081213}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:48:57 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:48:57 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run blushing-bug-219 at: http://127.0.0.1:5000/#/experiments/7/runs/e2c61efcca6a4c5a99dd0534c2e63fde\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.8982 - loss: 0.3388 - val_accuracy: 0.9523 - val_loss: 0.1591\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9371 - loss: 0.2197 - val_accuracy: 0.9600 - val_loss: 0.1354\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9450 - loss: 0.1955 - val_accuracy: 0.9621 - val_loss: 0.1294\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9485 - loss: 0.1851 - val_accuracy: 0.9633 - val_loss: 0.1256\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9503 - loss: 0.1839 - val_accuracy: 0.9649 - val_loss: 0.1261\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9540 - loss: 0.1721 - val_accuracy: 0.9670 - val_loss: 0.1226\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9541 - loss: 0.1749 - val_accuracy: 0.9667 - val_loss: 0.1249\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9574 - loss: 0.1634 - val_accuracy: 0.9711 - val_loss: 0.1102\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9609 - loss: 0.1533 - val_accuracy: 0.9695 - val_loss: 0.1091\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9601 - loss: 0.1556 - val_accuracy: 0.9718 - val_loss: 0.1130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:51:34 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:51:34 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:51:34,338] Trial 11 finished with value: 0.971833348274231 and parameters: {'learning_rate': 0.0030769580252432015, 'batch_size': 32, 'hidden_units': 256, 'dropout_rate': 0.34943872830237377}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:51:34 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:51:34 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run gregarious-wren-276 at: http://127.0.0.1:5000/#/experiments/7/runs/2a99efaeb5504c6688872bc79ad336ce\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.8576 - loss: 0.4804 - val_accuracy: 0.9442 - val_loss: 0.1915\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9375 - loss: 0.2132 - val_accuracy: 0.9580 - val_loss: 0.1336\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9522 - loss: 0.1562 - val_accuracy: 0.9673 - val_loss: 0.1090\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9621 - loss: 0.1251 - val_accuracy: 0.9723 - val_loss: 0.0914\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9679 - loss: 0.1047 - val_accuracy: 0.9741 - val_loss: 0.0874\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9725 - loss: 0.0903 - val_accuracy: 0.9754 - val_loss: 0.0810\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.9755 - loss: 0.0802 - val_accuracy: 0.9772 - val_loss: 0.0792\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9781 - loss: 0.0706 - val_accuracy: 0.9759 - val_loss: 0.0800\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0632 - val_accuracy: 0.9774 - val_loss: 0.0772\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9821 - loss: 0.0584 - val_accuracy: 0.9776 - val_loss: 0.0732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:54:08 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:54:08 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:54:08,499] Trial 12 finished with value: 0.9775833487510681 and parameters: {'learning_rate': 0.00023339756501537521, 'batch_size': 32, 'hidden_units': 256, 'dropout_rate': 0.3239164198185207}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:54:08 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:54:08 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run gifted-toad-693 at: http://127.0.0.1:5000/#/experiments/7/runs/305a16f3ef46490b9523be06e591bf62\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9094 - loss: 0.3026 - val_accuracy: 0.9514 - val_loss: 0.1665\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9431 - loss: 0.2031 - val_accuracy: 0.9579 - val_loss: 0.1501\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9508 - loss: 0.1846 - val_accuracy: 0.9663 - val_loss: 0.1253\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9559 - loss: 0.1718 - val_accuracy: 0.9629 - val_loss: 0.1426\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9571 - loss: 0.1676 - val_accuracy: 0.9684 - val_loss: 0.1286\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9571 - loss: 0.1675 - val_accuracy: 0.9705 - val_loss: 0.1176\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9626 - loss: 0.1501 - val_accuracy: 0.9700 - val_loss: 0.1167\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9626 - loss: 0.1563 - val_accuracy: 0.9681 - val_loss: 0.1617\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9638 - loss: 0.1531 - val_accuracy: 0.9693 - val_loss: 0.1362\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9648 - loss: 0.1473 - val_accuracy: 0.9707 - val_loss: 0.1417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:56:47 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:56:47 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:56:47,724] Trial 13 finished with value: 0.9707499742507935 and parameters: {'learning_rate': 0.0038012843805472142, 'batch_size': 32, 'hidden_units': 512, 'dropout_rate': 0.250061431280718}. Best is trial 4 with value: 0.9790833592414856.\n",
      "2025/12/12 12:56:47 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:56:47 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run powerful-stork-980 at: http://127.0.0.1:5000/#/experiments/7/runs/c9f30dd39fa7428098285a588f8c37ee\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8890 - loss: 0.3674 - val_accuracy: 0.9553 - val_loss: 0.1439\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9474 - loss: 0.1710 - val_accuracy: 0.9683 - val_loss: 0.1027\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9598 - loss: 0.1316 - val_accuracy: 0.9700 - val_loss: 0.1055\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9653 - loss: 0.1121 - val_accuracy: 0.9732 - val_loss: 0.0849\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9691 - loss: 0.0963 - val_accuracy: 0.9758 - val_loss: 0.0835\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9731 - loss: 0.0852 - val_accuracy: 0.9775 - val_loss: 0.0795\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9745 - loss: 0.0809 - val_accuracy: 0.9777 - val_loss: 0.0801\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9777 - loss: 0.0704 - val_accuracy: 0.9792 - val_loss: 0.0751\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9792 - loss: 0.0676 - val_accuracy: 0.9785 - val_loss: 0.0809\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 11ms/step - accuracy: 0.9780 - loss: 0.0676 - val_accuracy: 0.9768 - val_loss: 0.0828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 12:59:20 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 12:59:20 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 12:59:20,686] Trial 14 finished with value: 0.9791666865348816 and parameters: {'learning_rate': 0.0006794424421581074, 'batch_size': 32, 'hidden_units': 256, 'dropout_rate': 0.3731645352942806}. Best is trial 14 with value: 0.9791666865348816.\n",
      "2025/12/12 12:59:20 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 12:59:20 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run able-frog-832 at: http://127.0.0.1:5000/#/experiments/7/runs/17522f6672494ea498f32f32a6bd7210\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.7306 - loss: 0.8760 - val_accuracy: 0.9124 - val_loss: 0.3084\n",
      "Epoch 2/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.8826 - loss: 0.3929 - val_accuracy: 0.9314 - val_loss: 0.2293\n",
      "Epoch 3/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9115 - loss: 0.3016 - val_accuracy: 0.9452 - val_loss: 0.1886\n",
      "Epoch 4/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9256 - loss: 0.2552 - val_accuracy: 0.9520 - val_loss: 0.1629\n",
      "Epoch 5/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9360 - loss: 0.2199 - val_accuracy: 0.9558 - val_loss: 0.1483\n",
      "Epoch 6/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9417 - loss: 0.1947 - val_accuracy: 0.9591 - val_loss: 0.1335\n",
      "Epoch 7/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9470 - loss: 0.1769 - val_accuracy: 0.9629 - val_loss: 0.1229\n",
      "Epoch 8/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9521 - loss: 0.1596 - val_accuracy: 0.9646 - val_loss: 0.1161\n",
      "Epoch 9/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9546 - loss: 0.1475 - val_accuracy: 0.9672 - val_loss: 0.1095\n",
      "Epoch 10/10\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.9597 - loss: 0.1345 - val_accuracy: 0.9689 - val_loss: 0.1012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 13:01:51 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 13:01:51 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 13:01:51,737] Trial 15 finished with value: 0.968916654586792 and parameters: {'learning_rate': 8.131005701629847e-05, 'batch_size': 32, 'hidden_units': 256, 'dropout_rate': 0.40368543558473013}. Best is trial 14 with value: 0.9791666865348816.\n",
      "2025/12/12 13:01:51 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 13:01:51 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run skillful-stag-517 at: http://127.0.0.1:5000/#/experiments/7/runs/0cfeb5894ebf4e29af0e257807329062\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9010 - loss: 0.3488 - val_accuracy: 0.9573 - val_loss: 0.1477\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9606 - loss: 0.1346 - val_accuracy: 0.9648 - val_loss: 0.1143\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9728 - loss: 0.0888 - val_accuracy: 0.9731 - val_loss: 0.0880\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9806 - loss: 0.0658 - val_accuracy: 0.9749 - val_loss: 0.0788\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9846 - loss: 0.0495 - val_accuracy: 0.9764 - val_loss: 0.0791\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0405 - val_accuracy: 0.9783 - val_loss: 0.0718\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9900 - loss: 0.0317 - val_accuracy: 0.9776 - val_loss: 0.0775\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9916 - loss: 0.0266 - val_accuracy: 0.9799 - val_loss: 0.0739\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9935 - loss: 0.0205 - val_accuracy: 0.9812 - val_loss: 0.0752\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9938 - loss: 0.0193 - val_accuracy: 0.9809 - val_loss: 0.0739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 13:02:30 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 13:02:30 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 13:02:30,032] Trial 16 finished with value: 0.981166660785675 and parameters: {'learning_rate': 0.0005026943255003671, 'batch_size': 128, 'hidden_units': 512, 'dropout_rate': 0.12536848786318142}. Best is trial 16 with value: 0.981166660785675.\n",
      "2025/12/12 13:02:30 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 13:02:30 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run capable-quail-807 at: http://127.0.0.1:5000/#/experiments/7/runs/2f4fd4f6630a4ba3b084340b98a0b19a\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8043 - loss: 0.7169 - val_accuracy: 0.9005 - val_loss: 0.3823\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8584 - loss: 0.5383 - val_accuracy: 0.9197 - val_loss: 0.3435\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8672 - loss: 0.5135 - val_accuracy: 0.9080 - val_loss: 0.3681\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8657 - loss: 0.5239 - val_accuracy: 0.9064 - val_loss: 0.3965\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8617 - loss: 0.5339 - val_accuracy: 0.9138 - val_loss: 0.3987\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8661 - loss: 0.5180 - val_accuracy: 0.9142 - val_loss: 0.3603\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8555 - loss: 0.5566 - val_accuracy: 0.9093 - val_loss: 0.3697\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8637 - loss: 0.5256 - val_accuracy: 0.9147 - val_loss: 0.3397\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8694 - loss: 0.5092 - val_accuracy: 0.8964 - val_loss: 0.4341\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8605 - loss: 0.5429 - val_accuracy: 0.9143 - val_loss: 0.3947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 13:03:07 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 13:03:07 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 13:03:07,265] Trial 17 finished with value: 0.9196666479110718 and parameters: {'learning_rate': 0.03334286615386402, 'batch_size': 128, 'hidden_units': 128, 'dropout_rate': 0.10230570660686356}. Best is trial 16 with value: 0.981166660785675.\n",
      "2025/12/12 13:03:07 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 13:03:07 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run unique-sponge-842 at: http://127.0.0.1:5000/#/experiments/7/runs/9c9a65f2b3fb428394dd36986cf89984\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6988 - loss: 1.1399 - val_accuracy: 0.8914 - val_loss: 0.4364\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8756 - loss: 0.4413 - val_accuracy: 0.9166 - val_loss: 0.3050\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9010 - loss: 0.3443 - val_accuracy: 0.9283 - val_loss: 0.2580\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9148 - loss: 0.2978 - val_accuracy: 0.9350 - val_loss: 0.2302\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9245 - loss: 0.2623 - val_accuracy: 0.9417 - val_loss: 0.2075\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9321 - loss: 0.2355 - val_accuracy: 0.9463 - val_loss: 0.1900\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9376 - loss: 0.2154 - val_accuracy: 0.9498 - val_loss: 0.1747\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9434 - loss: 0.1961 - val_accuracy: 0.9536 - val_loss: 0.1630\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9465 - loss: 0.1826 - val_accuracy: 0.9557 - val_loss: 0.1545\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.9511 - loss: 0.1683 - val_accuracy: 0.9578 - val_loss: 0.1461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 13:03:44 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 13:03:44 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 13:03:44,600] Trial 18 finished with value: 0.9577500224113464 and parameters: {'learning_rate': 6.128977294150152e-05, 'batch_size': 128, 'hidden_units': 256, 'dropout_rate': 0.14803177532653766}. Best is trial 16 with value: 0.981166660785675.\n",
      "2025/12/12 13:03:44 INFO mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics. Set logger level to DEBUG for more details.\n",
      "2025/12/12 13:03:44 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run judicious-bear-417 at: http://127.0.0.1:5000/#/experiments/7/runs/90f349df97c2427988ee6ebd0a67d9fe\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "Training Pytorch model on GPU/TPU...\n",
      "\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.3461 - loss: 2.0060 - val_accuracy: 0.7293 - val_loss: 1.5024\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.6760 - loss: 1.2925 - val_accuracy: 0.8287 - val_loss: 0.8596\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.7680 - loss: 0.8711 - val_accuracy: 0.8658 - val_loss: 0.5837\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8115 - loss: 0.6760 - val_accuracy: 0.8848 - val_loss: 0.4642\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8351 - loss: 0.5732 - val_accuracy: 0.8964 - val_loss: 0.3973\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8524 - loss: 0.5100 - val_accuracy: 0.9028 - val_loss: 0.3578\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8662 - loss: 0.4633 - val_accuracy: 0.9086 - val_loss: 0.3296\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8754 - loss: 0.4295 - val_accuracy: 0.9132 - val_loss: 0.3077\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8805 - loss: 0.4056 - val_accuracy: 0.9162 - val_loss: 0.2918\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 10ms/step - accuracy: 0.8901 - loss: 0.3800 - val_accuracy: 0.9198 - val_loss: 0.2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/12 13:04:23 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 13:04:23 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n",
      "[I 2025-12-12 13:04:23,121] Trial 19 finished with value: 0.9198333621025085 and parameters: {'learning_rate': 1.1377478156038008e-05, 'batch_size': 128, 'hidden_units': 512, 'dropout_rate': 0.29212220301666797}. Best is trial 16 with value: 0.981166660785675.\n",
      "2025/12/12 13:04:23 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2025/12/12 13:04:23 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸƒ View run bouncy-midge-972 at: http://127.0.0.1:5000/#/experiments/7/runs/59d60d1f8dd44ce795fead058f6b8967\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n",
      "ğŸƒ View run aged-lark-122 at: http://127.0.0.1:5000/#/experiments/7/runs/e2b29108607b4bddae8414ba7d8cc4d5\n",
      "ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/7\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter optimization\n",
    "with mlflow.start_run():\n",
    "    mlflow.set_tag(\"optimization\", \"optuna\")\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=20)\n",
    "\n",
    "    # Log best parameters\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_val_accuracy\", study.best_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d764dcbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
