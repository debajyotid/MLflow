{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "110e8aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature, ModelSignature\n",
    "from mlflow.types import Schema, TensorSpec\n",
    "\n",
    "import optuna\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c53e73a",
   "metadata": {},
   "source": [
    "Let's load our training data FashionMNIST from torchvision, which has already been preprocessed into scale the [0, 1]. We then wrap the dataset into an instance of torch.utils.data.Dataloader.\n",
    "\n",
    "training_data = datasets.FashionMNIST(root=\"data\",  train=True,  download=True,  transform=ToTensor())\n",
    "\n",
    "test_data = datasets.FashionMNIST(root=\"data\",  train=False,  download=True,  transform=ToTensor())\n",
    "\n",
    "Since we have already the data earlier, we will reuse the same, as below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1a446a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the training data from open datasets\n",
    "training_data = datasets.FashionMNIST(root=\"/Users/debajyotidas/Library/CloudStorage/OneDrive-Personal/Online Courses/PyTorch/FashionMNIST\", train=True, download=True, transform=ToTensor())\n",
    "\n",
    "# Download the test data from open datasets\n",
    "test_data = datasets.FashionMNIST(root=\"/Users/debajyotidas/Library/CloudStorage/OneDrive-Personal/Online Courses/PyTorch/FashionMNIST\",train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3011b69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size: torch.Size([1, 28, 28])\n",
      "Size of training dataset: 60000\n",
      "Size of test dataset: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Image size: {training_data[0][0].shape}\")\n",
    "print(f\"Size of training dataset: {len(training_data)}\")\n",
    "print(f\"Size of test dataset: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98707581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "loss_fn = nn.CrossEntropyLoss() # Use CrossEntropyLoss when model outputs logits\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# Alternative using accelerate library if PyTorch version >= 2.6\n",
    "# device = torch.accelerator.current_accelerator().type if torch.accelerator.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecd62ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We wrap the dataset a Dataloader instance for batching purposes. Dataloader is a useful tool for data preprocessing.\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7644b4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/28 00:41:16 INFO mlflow.utils.credentials: Successfully connected to MLflow hosted tracking server! Host: https://dbc-e4fb7400-b637.cloud.databricks.com.\n"
     ]
    }
   ],
   "source": [
    "mlflow.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf3ca6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/2972025542579128', creation_time=1766783078458, experiment_id='2972025542579128', last_update_time=1766873123972, lifecycle_stage='active', name='/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-quickstart', tags={'mlflow.experiment.sourceName': '/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-quickstart',\n",
       " 'mlflow.experimentKind': 'custom_model_development',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'debajyoti.das.bookworm@gmail.com',\n",
       " 'mlflow.ownerId': '8680600426295472'}>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlflow.set_tracking_uri(\"databricks\")  # Telling MLflow to send the data into Databricks Workspace\n",
    "\n",
    "mlflow.set_experiment(\"/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-quickstart\")\n",
    "\n",
    "\n",
    "# In order to keep all of your artifacts within a single place, we can opt to use Unity Catalog's Volumes feature. Firstly, you need to create a Unity Catalog Volume (let's call it: test.mlflow.mlflow-pytorch-quickstart). Then, we can run the following code to start an experiment with the Unity Catalog Volume and log metrics to it. Note that your experiment name must follow the /Users/<your email>/<experiment_name> format when using a Databricks Workspace.\n",
    "\n",
    "#mlflow.create_experiment(\"/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-quickstart\",artifact_location=\"dbfs:/Volumes/test/mlflow/mlflow-pytorch-quickstart\")\n",
    "#mlflow.set_experiment(\"/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-quickstart\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e875f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(nn.Conv2d(1, 8, kernel_size=3),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv2d(8, 16, kernel_size=3),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Flatten(),\n",
    "                                   nn.LazyLinear(10),\n",
    "                                   )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6093e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, metrics_fn, optimizer, epoch):\n",
    "  \"\"\"Train the model on a single pass of the dataloader.\n",
    "\n",
    "  Args:\n",
    "      dataloader: an instance of `torch.utils.data.DataLoader`, containing the training data.\n",
    "      model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "      loss_fn: a callable, the loss function.\n",
    "      metrics_fn: a callable, the metrics function.\n",
    "      optimizer: an instance of `torch.optim.Optimizer`, the optimizer used for training.\n",
    "      epoch: an integer, the current epoch number.\n",
    "  \"\"\"\n",
    "  model.train()\n",
    "  for batch, (X, y) in enumerate(dataloader):\n",
    "      X = X.to(device)\n",
    "      y = y.to(device)\n",
    "\n",
    "      pred = model(X)\n",
    "      loss = loss_fn(pred, y)\n",
    "      accuracy = metrics_fn(pred, y)\n",
    "\n",
    "      # Backpropagation.\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      if batch % 100 == 0:\n",
    "          loss_value = loss.item()\n",
    "          current = batch\n",
    "          step = batch // 100 * (epoch + 1)\n",
    "          mlflow.log_metric(\"loss\", f\"{loss_value:2f}\", step=step)\n",
    "          mlflow.log_metric(\"accuracy\", f\"{accuracy:2f}\", step=step)\n",
    "          print(f\"loss: {loss_value:2f} accuracy: {accuracy:2f} [{current} / {len(dataloader)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14f55d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader, model, loss_fn, metrics_fn, epoch):\n",
    "  \"\"\"Evaluate the model on a single pass of the dataloader.\n",
    "\n",
    "  Args:\n",
    "      dataloader: an instance of `torch.utils.data.DataLoader`, containing the eval data.\n",
    "      model: an instance of `torch.nn.Module`, the model to be trained.\n",
    "      loss_fn: a callable, the loss function.\n",
    "      metrics_fn: a callable, the metrics function.\n",
    "      epoch: an integer, the current epoch number.\n",
    "  \"\"\"\n",
    "  num_batches = len(dataloader)\n",
    "  model.eval()\n",
    "  eval_loss = 0\n",
    "  eval_accuracy = 0\n",
    "  with torch.no_grad():\n",
    "      for X, y in dataloader:\n",
    "          X = X.to(device)\n",
    "          y = y.to(device)\n",
    "          pred = model(X)\n",
    "          eval_loss += loss_fn(pred, y).item()\n",
    "          eval_accuracy += metrics_fn(pred, y)\n",
    "\n",
    "  eval_loss /= num_batches\n",
    "  eval_accuracy /= num_batches\n",
    "  mlflow.log_metric(\"eval_loss\", f\"{eval_loss:2f}\", step=epoch)\n",
    "  mlflow.log_metric(\"eval_accuracy\", f\"{eval_accuracy:2f}\", step=epoch)\n",
    "\n",
    "  print(f\"Eval metrics: Accuracy: {eval_accuracy:.2f}, Avg loss: {eval_loss:2f} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5538c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "metric_fn = Accuracy(task=\"multiclass\", num_classes=10).to(device)\n",
    "model = ImageClassifier().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2db3989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output schemas, in case infer_signature is not working as desired\n",
    "input_schema = Schema([TensorSpec(np.dtype(np.float32), (1, 1, 28, 28))])\n",
    "output_schema = Schema([TensorSpec(np.dtype(np.float32), (1, 1, 10))])\n",
    "signature = ModelSignature(inputs=input_schema, outputs=output_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17aa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1-------------------------------\n",
      "loss: 0.488221 accuracy: 0.796875 [0 / 938]\n",
      "loss: 0.606702 accuracy: 0.734375 [100 / 938]\n",
      "loss: 0.394706 accuracy: 0.843750 [200 / 938]\n",
      "loss: 0.676098 accuracy: 0.750000 [300 / 938]\n",
      "loss: 0.617312 accuracy: 0.671875 [400 / 938]\n",
      "loss: 0.626373 accuracy: 0.796875 [500 / 938]\n",
      "loss: 0.605164 accuracy: 0.734375 [600 / 938]\n",
      "loss: 0.631529 accuracy: 0.781250 [700 / 938]\n",
      "loss: 0.661463 accuracy: 0.765625 [800 / 938]\n",
      "loss: 0.565829 accuracy: 0.750000 [900 / 938]\n",
      "Eval metrics: Accuracy: 0.78, Avg loss: 0.591617 \n",
      "Epoch 2-------------------------------\n",
      "loss: 0.467491 accuracy: 0.812500 [0 / 938]\n",
      "loss: 0.571770 accuracy: 0.734375 [100 / 938]\n",
      "loss: 0.376837 accuracy: 0.875000 [200 / 938]\n",
      "loss: 0.646474 accuracy: 0.750000 [300 / 938]\n",
      "loss: 0.602310 accuracy: 0.718750 [400 / 938]\n",
      "loss: 0.606144 accuracy: 0.781250 [500 / 938]\n",
      "loss: 0.574763 accuracy: 0.765625 [600 / 938]\n",
      "loss: 0.626924 accuracy: 0.812500 [700 / 938]\n",
      "loss: 0.669579 accuracy: 0.765625 [800 / 938]\n",
      "loss: 0.532972 accuracy: 0.765625 [900 / 938]\n",
      "Eval metrics: Accuracy: 0.78, Avg loss: 0.583653 \n",
      "Epoch 3-------------------------------\n",
      "loss: 0.460299 accuracy: 0.812500 [0 / 938]\n",
      "loss: 0.550114 accuracy: 0.734375 [100 / 938]\n",
      "loss: 0.366108 accuracy: 0.875000 [200 / 938]\n",
      "loss: 0.623608 accuracy: 0.750000 [300 / 938]\n",
      "loss: 0.589534 accuracy: 0.703125 [400 / 938]\n",
      "loss: 0.589151 accuracy: 0.781250 [500 / 938]\n",
      "loss: 0.553409 accuracy: 0.765625 [600 / 938]\n",
      "loss: 0.622753 accuracy: 0.812500 [700 / 938]\n",
      "loss: 0.674774 accuracy: 0.750000 [800 / 938]\n",
      "loss: 0.509950 accuracy: 0.781250 [900 / 938]\n",
      "Eval metrics: Accuracy: 0.78, Avg loss: 0.578477 \n",
      "üèÉ View run dashing-sheep-521 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/2972025542579128/runs/497003eb9be14979bb44278a2f5ec3bb\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/2972025542579128\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    params = {\"epochs\": epochs,\n",
    "              \"learning_rate\": 1e-3,\n",
    "              \"batch_size\": batch_size,\n",
    "              \"loss_function\": loss_fn.__class__.__name__,\n",
    "              \"metric_function\": metric_fn.__class__.__name__,\n",
    "              \"optimizer\": \"SGD\"}\n",
    "    \n",
    "    # Log training parameters.\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log model summary.\n",
    "    with open(\"/Users/debajyotidas/Library/CloudStorage/OneDrive-Personal/Online Courses/MLFlow/model_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model)))\n",
    "    mlflow.log_artifact(\"/Users/debajyotidas/Library/CloudStorage/OneDrive-Personal/Online Courses/MLFlow/model_summary.txt\")\n",
    "    \n",
    "    for t in range(epochs):\n",
    "        print(f\"Epoch {t + 1}-------------------------------\")\n",
    "        train(train_dataloader, model, loss_fn, metric_fn, optimizer, epoch=t)\n",
    "        evaluate(test_dataloader, model, loss_fn, metric_fn, epoch=0)\n",
    "\n",
    "    # Build model signature by inferring input and output schema\n",
    "    # Create sample input and predictions\n",
    "    # sample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\n",
    "\n",
    "    # # Get model output - convert tensor to numpy\n",
    "    # with torch.no_grad():\n",
    "    #     output = model(torch.tensor(sample_input))\n",
    "    #     sample_output = output.numpy()\n",
    "\n",
    "    # # Infer signature automatically\n",
    "    # signature = infer_signature(sample_input, sample_output)\n",
    "        \n",
    "    # Save the trained model to MLflow.\n",
    "    model_info = mlflow.pytorch.log_model(model, name=\"PyTorch_MLFlow_model\", signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afe41509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7c8cc9abdd498fb035ce253e93dc25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ee501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "# Add batch dimension to the input for prediction\n",
    "input_data = np.expand_dims(training_data[0][0].numpy(), axis=0)\n",
    "outputs = loaded_model.predict(input_data)\n",
    "predicted, actual = classes[outputs[0].argmax()], classes[training_data[0][1]]\n",
    "print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f020dcfd",
   "metadata": {},
   "source": [
    "# Complete PyTorch Logging Example\n",
    "\n",
    "Earlier we saw a simple implementation of logging model training metrics on Databricks using CNNs implemented using PyTorch-MLFlow-Databricks. Below we will implement something similar, but using standard DNNs and we will log many more metrices and visualisations.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b3593a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='dbfs:/databricks/mlflow-tracking/1304458245524678', creation_time=1766882239452, experiment_id='1304458245524678', last_update_time=1766882394802, lifecycle_stage='active', name='/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-complete-v2', tags={'mlflow.experiment.sourceName': '/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-complete-v2',\n",
       " 'mlflow.experimentType': 'MLFLOW_EXPERIMENT',\n",
       " 'mlflow.ownerEmail': 'debajyoti.das.bookworm@gmail.com',\n",
       " 'mlflow.ownerId': '8680600426295472'}>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mlflow.create_experiment(\"/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-complete\",artifact_location=\"dbfs:/Volumes/test/mlflow/mlflow-pytorch-complete\")\n",
    "mlflow.set_experiment(\"/Users/debajyoti.das.bookworm@gmail.com/mlflow-pytorch-complete-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ccc5fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(28 * 28, 512),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(512, 512),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(512, 10))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f507d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLflowTracker:\n",
    "    def __init__(self, model, classes):\n",
    "        self.model = model\n",
    "        self.classes = classes\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_accs = []\n",
    "        self.val_accs = []\n",
    "\n",
    "    def log_epoch(self, epoch, train_loss, train_acc, val_loss, val_acc):\n",
    "        \"\"\"Log metrics for an epoch.\"\"\"\n",
    "        self.train_losses.append(train_loss)\n",
    "        self.val_losses.append(val_loss)\n",
    "        self.train_accs.append(train_acc)\n",
    "        self.val_accs.append(val_acc)\n",
    "\n",
    "        mlflow.log_metrics(\n",
    "            {\n",
    "                \"train_loss\": train_loss,\n",
    "                \"train_accuracy\": train_acc,\n",
    "                \"val_loss\": val_loss,\n",
    "                \"val_accuracy\": val_acc,\n",
    "            },\n",
    "            step=epoch,\n",
    "        )\n",
    "\n",
    "    def log_confusion_matrix(self, val_loader, device):\n",
    "        \"\"\"Generate and log confusion matrix.\"\"\"\n",
    "        self.model.eval()\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                targets = targets.to(device)\n",
    "                outputs = self.model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        # Create confusion matrix\n",
    "        cm = confusion_matrix(all_targets, all_preds)\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(\n",
    "            cm,\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=self.classes,\n",
    "            yticklabels=self.classes,\n",
    "        )\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.ylabel(\"True Label\")\n",
    "        plt.xlabel(\"Predicted Label\")\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save and log\n",
    "        plt.savefig(\"confusion_matrix.png\")\n",
    "        mlflow.log_artifact(\"confusion_matrix.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def log_training_curves(self):\n",
    "        \"\"\"Generate and log training curves.\"\"\"\n",
    "        plt.figure(figsize=(12, 5))\n",
    "\n",
    "        # Loss subplot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(self.train_losses, label=\"Train Loss\")\n",
    "        plt.plot(self.val_losses, label=\"Validation Loss\")\n",
    "        plt.title(\"Loss Curves\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.legend()\n",
    "\n",
    "        # Accuracy subplot\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(self.train_accs, label=\"Train Accuracy\")\n",
    "        plt.plot(self.val_accs, label=\"Validation Accuracy\")\n",
    "        plt.title(\"Accuracy Curves\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Accuracy (%)\")\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"training_curves.png\")\n",
    "        mlflow.log_artifact(\"training_curves.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5f9f49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "params = {\"epochs\": 3,\n",
    "          \"learning_rate\": 1e-3,\n",
    "          \"batch_size\": batch_size,\n",
    "          \"optimizer\": \"SGD\",\n",
    "          \"model_type\": \"MLP\",\n",
    "          \"hidden_units\": [512, 512]}\n",
    "\n",
    "# Create and prepare model\n",
    "model = NeuralNetwork().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=params[\"learning_rate\"])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4ca140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tracker\n",
    "tracker = MLflowTracker(\n",
    "    model,\n",
    "    classes=[\n",
    "        \"T-shirt\",\n",
    "        \"Trouser\",\n",
    "        \"Pullover\",\n",
    "        \"Dress\",\n",
    "        \"Coat\",\n",
    "        \"Sandal\",\n",
    "        \"Shirt\",\n",
    "        \"Sneaker\",\n",
    "        \"Bag\",\n",
    "        \"Ankle boot\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b74321f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Train Loss: 0.9403, Train Acc: 67.44%, Val Loss: 0.9160, Val Acc: 67.14%\n",
      "Epoch 2/3, Train Loss: 0.8760, Train Acc: 68.72%, Val Loss: 0.8625, Val Acc: 68.00%\n",
      "Epoch 3/3, Train Loss: 0.8283, Train Acc: 70.06%, Val Loss: 0.8217, Val Acc: 69.39%\n",
      "üèÉ View run bright-elk-717 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/2b957c18247f44ebbf863aa673b546bb\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    }
   ],
   "source": [
    "# Training and logging\n",
    "with mlflow.start_run():\n",
    "    # 1. Log parameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # 2. Log model architecture\n",
    "    with open(\"model_fmnist_pt_mlf_cmplt_summary.txt\", \"w\") as f:\n",
    "        f.write(str(summary(model, input_size=(1, 1, 28, 28), device=device)))\n",
    "    mlflow.log_artifact(\"model_fmnist_pt_mlf_cmplt_summary.txt\")\n",
    "\n",
    "    # 3. Training loop with metric logging\n",
    "    for epoch in range(params[\"epochs\"]):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Calculate metrics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "            # Log batch metrics (every 100 batches)\n",
    "            if batch_idx % 100 == 0:\n",
    "                batch_loss = train_loss / (batch_idx + 1)\n",
    "                batch_acc = 100.0 * correct / total\n",
    "                mlflow.log_metrics({\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n",
    "                                   step=epoch * len(train_dataloader) + batch_idx)\n",
    "                \n",
    "        # Calculate epoch metrics\n",
    "        epoch_loss = train_loss / len(train_dataloader)\n",
    "        epoch_acc = 100.0 * correct / total\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for data, target in test_dataloader:\n",
    "                data = data.to(device)\n",
    "                target = target.to(device)\n",
    "                output = model(data)\n",
    "                loss = loss_fn(output, target)\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = output.max(1)\n",
    "                val_total += target.size(0)\n",
    "                val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Calculate and log epoch validation metrics\n",
    "        val_loss = val_loss / len(test_dataloader)\n",
    "        val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "        # Log epoch metrics\n",
    "        mlflow.log_metrics({\"train_loss\": epoch_loss,\n",
    "                            \"train_accuracy\": epoch_acc,\n",
    "                            \"val_loss\": val_loss,\n",
    "                            \"val_accuracy\": val_acc}, step=epoch)\n",
    "        # Log epoch metrics\n",
    "        tracker.log_epoch(epoch, epoch_loss, epoch_acc, val_loss, val_acc)\n",
    "\n",
    "        # Log final visualizations\n",
    "        tracker.log_confusion_matrix(test_dataloader, device)\n",
    "        tracker.log_training_curves()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{params['epochs']}, \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        \n",
    "    # Create sample input and predictions\n",
    "    sample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\n",
    "\n",
    "    # Get model output - convert tensor to numpy\n",
    "    with torch.no_grad():\n",
    "        output = model(torch.tensor(sample_input).to(device))\n",
    "        sample_output = output.cpu().numpy()\n",
    "\n",
    "    # Infer signature automatically\n",
    "    signature = infer_signature(sample_input, sample_output)\n",
    "        \n",
    "    # 5. Log the trained model\n",
    "    model_info = mlflow.pytorch.log_model(model, name=\"model\", signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "654548cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 69.39%\n"
     ]
    }
   ],
   "source": [
    "# 6. Final evaluation\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        test_total += target.size(0)\n",
    "        test_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "# Calculate and log final test metrics\n",
    "test_loss = test_loss / len(test_dataloader)\n",
    "test_acc = 100.0 * test_correct / test_total\n",
    "\n",
    "mlflow.log_metrics({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n",
    "\n",
    "print(f\"Final Test Accuracy: {test_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98561acf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2708fb8310ee42ef9b4745d7ae68bb57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: [[ 0.7429988  -3.2293518   2.366237   -0.9774927   1.4614708  -0.17526606\n",
      "   2.129318   -3.2427442   2.9796162  -1.5677054 ]]\n"
     ]
    }
   ],
   "source": [
    "# Load and use the model\n",
    "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
    "\n",
    "# Make predictions\n",
    "sample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\n",
    "predictions = loaded_model.predict(sample_input)\n",
    "print(\"Predictions:\", predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "054c7752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run stylish-goose-867 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/5a3b626637b34854b29c19fa24510558\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    }
   ],
   "source": [
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3224e4",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization\n",
    "Combine PyTorch with hyperparameter optimization tools while tracking everything in MLflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02b5a242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class NeuralNetworkOptim(nn.Module):\n",
    "    def __init__(self, hidden_size):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(nn.Linear(28 * 28, out_features=hidden_size),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(hidden_size, hidden_size),\n",
    "                                               nn.ReLU(),\n",
    "                                               nn.Linear(hidden_size, 10))\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f037e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, loss_fn, optimizer, epoch, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Calculate metrics\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "\n",
    "        # Log batch metrics (every 100 batches)\n",
    "        if batch_idx % 100 == 0:\n",
    "            batch_loss = train_loss / (batch_idx + 1)\n",
    "            batch_acc = 100.0 * correct / total\n",
    "            mlflow.log_metrics({\"batch_loss\": batch_loss, \"batch_accuracy\": batch_acc},\n",
    "                                step=epoch * len(dataloader) + batch_idx)\n",
    "            \n",
    "    # Calculate epoch metrics\n",
    "    epoch_loss = train_loss / len(dataloader)\n",
    "    epoch_acc = 100.0 * correct / total\n",
    "\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22352a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data = data.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            val_total += target.size(0)\n",
    "            val_correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    # Calculate and log epoch validation metrics\n",
    "    val_loss = val_loss / len(dataloader)\n",
    "    val_acc = 100.0 * val_correct / val_total\n",
    "\n",
    "    return val_loss, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7318009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, train_loader, val_loader, device):\n",
    "    # Suggest hyperparameters\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"SGD\"])\n",
    "    hidden_size = trial.suggest_categorical(\"hidden_size\", [128, 256, 512])\n",
    "\n",
    "    with mlflow.start_run(nested=True):\n",
    "        # Log hyperparameters\n",
    "        params = {\"lr\": lr,\n",
    "                  \"optimizer\": optimizer_name,\n",
    "                  \"hidden_size\": hidden_size,\n",
    "                  \"batch_size\": 64,\n",
    "                  \"epochs\": 3}\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        # Create model\n",
    "        model = NeuralNetworkOptim(hidden_size=hidden_size).to(device)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Configure optimizer\n",
    "        if optimizer_name == \"Adam\":\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "        else:\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "        # Train for a few epochs\n",
    "        best_val_acc = 0\n",
    "        for epoch in range(params[\"epochs\"]):\n",
    "            # Training code (abbreviated)...\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, loss_fn, optimizer, epoch, device)\n",
    "            val_loss, val_acc = evaluate(model, val_loader, loss_fn, device)\n",
    "\n",
    "            mlflow.log_metrics({\"train_loss\": train_loss,\n",
    "                                \"train_acc\": train_acc,\n",
    "                                \"val_loss\": val_loss,\n",
    "                                \"val_acc\": val_acc},\n",
    "                                step=epoch)\n",
    "\n",
    "            best_val_acc = max(best_val_acc, val_acc)\n",
    "\n",
    "        # Final logging\n",
    "        mlflow.log_metric(\"best_val_acc\", best_val_acc)\n",
    "\n",
    "        #Getting model signature and logging the model\n",
    "        sample_input = np.random.uniform(size=[1, 28, 28]).astype(np.float32)\n",
    "        # Get model output - convert tensor to numpy\n",
    "        with torch.no_grad():\n",
    "            output = model(torch.tensor(sample_input).to(device))\n",
    "            sample_output = output.cpu().numpy()\n",
    "        signature = infer_signature(sample_input, sample_output)\n",
    "        \n",
    "        mlflow.pytorch.log_model(model, name=\"model\", signature=signature)\n",
    "\n",
    "        return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c5abe82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:53:38,819] A new study created in memory with name: no-name-8fb035da-127f-44cf-95d1-82573f293234\n",
      "[I 2025-12-28 11:54:09,725] Trial 0 finished with value: 23.19 and parameters: {'lr': 0.0002580915655688361, 'optimizer': 'SGD', 'hidden_size': 128}. Best is trial 0 with value: 23.19.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run dazzling-snake-633 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/d95508865f844a6187a3cede1471df91\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:54:39,776] Trial 1 finished with value: 79.91 and parameters: {'lr': 0.012758063061313727, 'optimizer': 'SGD', 'hidden_size': 512}. Best is trial 1 with value: 79.91.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run abrasive-snake-997 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/cf98c3ebfc8b44ee85fb3e7ef1d4e689\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:55:10,187] Trial 2 finished with value: 80.87 and parameters: {'lr': 0.03384407825078113, 'optimizer': 'SGD', 'hidden_size': 512}. Best is trial 2 with value: 80.87.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run redolent-smelt-770 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/ef4ed091fa9149c7a5b2581afbae7f02\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:55:46,411] Trial 3 finished with value: 86.36 and parameters: {'lr': 0.000511899721380269, 'optimizer': 'Adam', 'hidden_size': 512}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bemused-wren-987 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/afedd44739f84f5593138488d522215d\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:56:17,966] Trial 4 finished with value: 80.14 and parameters: {'lr': 0.025506207236455355, 'optimizer': 'SGD', 'hidden_size': 128}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run mysterious-kite-813 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/78a0b35d91c14beab3992928e72a014a\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:56:50,855] Trial 5 finished with value: 83.86 and parameters: {'lr': 0.010717708845290504, 'optimizer': 'Adam', 'hidden_size': 128}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run entertaining-asp-294 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/d4140b3b3e9d4e6ea5d1ad611c8f6d42\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:57:24,369] Trial 6 finished with value: 85.52 and parameters: {'lr': 0.005435907788520431, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run wistful-croc-109 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/5ad1b37777df4e6cbd114c8303bdc35b\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:57:56,782] Trial 7 finished with value: 84.68 and parameters: {'lr': 0.009376734231539367, 'optimizer': 'Adam', 'hidden_size': 128}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run lyrical-lynx-281 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/771b8b5448984ef7a8e04e05b76db9f7\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:58:26,639] Trial 8 finished with value: 44.67 and parameters: {'lr': 0.00024319342152441444, 'optimizer': 'SGD', 'hidden_size': 256}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rumbling-pig-632 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/c33992d04d4941ba8c239a2f616775cb\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:58:59,853] Trial 9 finished with value: 77.37 and parameters: {'lr': 0.037149232053758675, 'optimizer': 'Adam', 'hidden_size': 128}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run popular-mole-483 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/d4147f0b9cac45dfac28881273154fa6\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 11:59:33,372] Trial 10 finished with value: 80.1 and parameters: {'lr': 1.3300763449876837e-05, 'optimizer': 'Adam', 'hidden_size': 512}. Best is trial 3 with value: 86.36.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run clumsy-jay-653 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/2da35b688094487db27094d54b57b602\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:00:06,377] Trial 11 finished with value: 86.47 and parameters: {'lr': 0.0015572937151785125, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run learned-colt-111 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/b6fc76048087498b83a6a704dd464c17\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:00:39,450] Trial 12 finished with value: 86.04 and parameters: {'lr': 0.0010640140005682718, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run lyrical-shark-961 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/3771ab22f1f94bf48c633cd16e82c315\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:01:13,555] Trial 13 finished with value: 86.13 and parameters: {'lr': 0.0014294197761096417, 'optimizer': 'Adam', 'hidden_size': 512}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run amusing-crane-244 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/0ea4a6aa622f4b3d991f8d6c28940137\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:01:46,703] Trial 14 finished with value: 85.58 and parameters: {'lr': 0.00019062921154615385, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run thundering-cat-982 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/6b47ab15c1c946c2bdb2959e4ecab729\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:02:20,654] Trial 15 finished with value: 83.36 and parameters: {'lr': 3.6242629028115284e-05, 'optimizer': 'Adam', 'hidden_size': 512}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run thundering-worm-388 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/3b4c89db490b49518722f31a46e79d5b\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:02:53,883] Trial 16 finished with value: 85.51 and parameters: {'lr': 0.003513911410327342, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run languid-dove-457 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/e2ba3ef3e45f460e9c171d6ada914be0\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:03:27,019] Trial 17 finished with value: 83.99 and parameters: {'lr': 8.362680678000618e-05, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run vaunted-conch-859 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/f0ac3769f056439ea31689f2f1bac6b2\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:04:00,693] Trial 18 finished with value: 86.15 and parameters: {'lr': 0.0005398302726771358, 'optimizer': 'Adam', 'hidden_size': 512}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run receptive-skunk-329 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/043da3f2232f4443838b844e235fe2f6\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-28 12:04:33,716] Trial 19 finished with value: 85.48 and parameters: {'lr': 0.0016393332505129647, 'optimizer': 'Adam', 'hidden_size': 256}. Best is trial 11 with value: 86.47.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run secretive-trout-503 at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/2709e0b01bd14020a1e6a5a48462e516\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n",
      "üèÉ View run hyperparam_optimization at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678/runs/acb255ca7ec1487abe1162e2393238b3\n",
      "üß™ View experiment at: https://dbc-e4fb7400-b637.cloud.databricks.com/ml/experiments/1304458245524678\n"
     ]
    }
   ],
   "source": [
    "# Execute hyperparameter search\n",
    "with mlflow.start_run(run_name=\"hyperparam_optimization\"):\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    objective_func = partial(objective, train_loader=train_dataloader, val_loader=test_dataloader, device=device)\n",
    "    study.optimize(objective_func, n_trials=20)\n",
    "\n",
    "    # Log best parameters and score\n",
    "    mlflow.log_params(study.best_params)\n",
    "    mlflow.log_metric(\"best_val_accuracy\", study.best_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
